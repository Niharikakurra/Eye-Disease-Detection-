# -*- coding: utf-8 -*-
"""eye_disease_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ah9pkgyxr3CKBkdelVuHS5wQztO5DQyB
"""



from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive
import os

# Mount Google Drive
drive.mount('/content/drive')

# Define dataset path (update this path based on your Google Drive location)
dataset_path = "/content/drive/MyDrive/Eye_Disease_Dataset"

# Check if dataset is correctly mounted
print("Dataset files:", os.listdir(dataset_path))

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define image size and batch size
IMG_SIZE = (224, 224)  # Resize images to match InceptionV3, VGG19, etc.
BATCH_SIZE = 32

# Data Augmentation and Loading
train_datagen = ImageDataGenerator(
    rescale=1./255,   # Normalize pixel values
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2  # Split some data for validation
)

# Load training data
train_generator = train_datagen.flow_from_directory(
    os.path.join(dataset_path, 'train'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'  # Use 80% for training
)

# Load validation data
validation_generator = train_datagen.flow_from_directory(
    os.path.join(dataset_path, 'train'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'  # Use 20% for validation
)

# Load testing data
test_datagen = ImageDataGenerator(rescale=1./255)  # Only normalize for testing
test_generator = test_datagen.flow_from_directory(
    os.path.join(dataset_path, 'val'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

!pip install tensorflow keras numpy pandas opencv-python matplotlib

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG19
import os

train_dir = os.path.join(dataset_path, 'train')
test_dir = os.path.join(dataset_path, 'val')

img_size = (224, 224)
batch_size = 32

train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical')

test_generator = test_datagen.flow_from_directory(
    test_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical')

base_model = VGG19(input_shape=(224, 224, 3), weights='imagenet', include_top=False)

for layer in base_model.layers:
    layer.trainable = False  # Freeze the pre-trained layers

model = Sequential([
    base_model,
    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(4, activation='softmax')  # 4 classes: Normal, Cataract, DR, Glaucoma
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(train_generator, validation_data=test_generator, epochs=10)

model.save('/content/drive/MyDrive/evgg.h5')

model.save("eye_disease_model.h5")

loss, accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {accuracy * 100:.2f}%")